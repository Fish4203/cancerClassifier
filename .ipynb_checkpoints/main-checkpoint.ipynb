{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model \n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(tf.__version__)\n",
    "# https://www.tensorflow.org/tutorials/images/classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0098d39c",
   "metadata": {},
   "source": [
    "# Multi cell model \n",
    "Importing the data and spliting it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b839057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 27\n",
    "img_width = 27\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/home/fish/programing/cancerClassifier/splitData/',\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/home/fish/programing/cancerClassifier/splitData/',\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa9f2ff",
   "metadata": {},
   "source": [
    "normalising the data to 0 to 1 insted of 0 to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0baf4f",
   "metadata": {},
   "source": [
    "## The 4 models  \n",
    "Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba59062",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(64, activation='gelu'),\n",
    "  layers.Dense(64, activation='gelu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.load_weights('./checkpoints/multi2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3cbe31",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f14036",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(256, activation='gelu'),\n",
    "  layers.Dense(256, activation='gelu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.load_weights('./checkpoints/multi1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b60897",
   "metadata": {},
   "source": [
    "Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(32, (3,3), padding='same', activation='relu', kernel_regularizer=L2(0.01)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, (3,3), padding='same', activation='relu', kernel_regularizer=L2(0.01)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, (3,3), padding='same', activation='relu', kernel_regularizer=L2(0.01)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(256, activation='gelu'),\n",
    "  layers.Dense(256, activation='gelu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.load_weights('./checkpoints/multi3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96361ca4",
   "metadata": {},
   "source": [
    "Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea2877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(256, activation='gelu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(256, activation='gelu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.load_weights('./checkpoints/multi4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c5adc2",
   "metadata": {},
   "source": [
    "## Training the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2802670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs=15\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/multi3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1516b3a3",
   "metadata": {},
   "source": [
    "# IsCancer model training\n",
    "importing the data and spliting it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905576c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 27\n",
    "img_width = 27\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/home/fish/programing/cancerClassifier/cdata/',\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/home/fish/programing/cancerClassifier/cdata/',\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bab1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9c231",
   "metadata": {},
   "source": [
    "normalising the data to 0 to 1 insted of 0 to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3394d621",
   "metadata": {},
   "source": [
    "## The 4 models  \n",
    "Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6505db",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(64, activation='gelu'),\n",
    "  layers.Dense(64, activation='gelu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.load_weights('./checkpoints/c1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341bc764",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb21e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(256, activation='gelu'),\n",
    "  layers.Dense(256, activation='gelu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.load_weights('./checkpoints/c2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4433ffbf",
   "metadata": {},
   "source": [
    "Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu', kernel_regularizer=L2(0.01)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu', kernel_regularizer=L2(0.01)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, 3, padding='same', activation='relu', kernel_regularizer=L2(0.01)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(256, activation='gelu'),\n",
    "  layers.Dense(256, activation='gelu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.load_weights('./checkpoints/c3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6290a739",
   "metadata": {},
   "source": [
    "Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7df00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(256, activation='gelu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(256, activation='gelu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.load_weights('./checkpoints/c4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d0c46",
   "metadata": {},
   "source": [
    "## Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3b5a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs=15\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e47df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/c3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0b70db",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "To validate the metrics of a iscancer model use the singel training data and run the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b3983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = 0\n",
    "divs = 0\n",
    "for batch in val_ds.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    ypred = []\n",
    "    for i in yhat:\n",
    "        ypred.append(round(i[0],0))\n",
    "#     print(y, ypred)\n",
    "#     print(f1_score(y, ypred, average='weighted'))\n",
    "    out += f1_score(y, ypred, average='weighted')\n",
    "    divs += 1\n",
    "\n",
    "print(\"f1:\", out/divs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94d50b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re = Recall()\n",
    "for batch in val_ds.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    ypred = []\n",
    "    re.update_state(y, yhat)\n",
    "\n",
    "print(\"recall:\", re.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e27ff2e",
   "metadata": {},
   "source": [
    "To validate the metrics of a multi cell model use the multi training data and run the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329c941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re = Recall()\n",
    "for batch in val_ds.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    ypred = []\n",
    "    for i in yhat:\n",
    "        ypred.append(np.argmax(i))\n",
    "# #     print(y, ypred)\n",
    "    re.update_state(y, ypred)\n",
    "\n",
    "print(\"recall:\", re.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d99ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = 0\n",
    "divs = 0\n",
    "for batch in val_ds.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    ypred = []\n",
    "    for i in yhat:\n",
    "        ypred.append(np.argmax(i))\n",
    "#     print(y, ypred)\n",
    "#     print(f1_score(y, ypred, average='weighted'))\n",
    "    out += f1_score(y, ypred, average='weighted')\n",
    "    divs += 1\n",
    "\n",
    "print(\"f1:\", out/divs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b3eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f86c9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a6a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec6f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1643bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b76694db",
   "metadata": {},
   "source": [
    "# helper things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc5c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "src_path = r\"/home/fish/programing/cancerClassifier/patch_images/\"\n",
    "dst_path = r\"/home/fish/programing/cancerClassifier/cdata/\"\n",
    "\n",
    "# split the dataset \n",
    "# dont runn unless you wanna split the data again (you dont)\n",
    "with open('data_labels_mainData.csv', 'r') as file:\n",
    "    \n",
    "    for line in file.readlines()[1:]:\n",
    "        li = line.split(',')\n",
    "        if li[3] == '0\\n':\n",
    "            shutil.copyfile(src_path + str(li[2]), dst_path + 'N' + '/' + str(li[2]))\n",
    "        else:\n",
    "            shutil.copyfile(src_path + str(li[2]), dst_path + 'Y' + '/' + str(li[2]))\n",
    "    \n",
    "        \n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
